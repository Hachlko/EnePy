import json
import os
import re
import pyttsx3
import time
import webbrowser
import speech_recognition as sr
from dotenv import load_dotenv

load_dotenv()
from datetime import datetime
from langchain_community.chat_models import ChatOllama
from brave_search import brave_search
from langchain.schema import HumanMessage, SystemMessage
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from hotword_listener import hotword_detected
from random import sample

# ----------------- M√©moire simple ----------------- #
MEMORY_FILE = "ene_memory.json"


def load_memory():
    if os.path.exists(MEMORY_FILE):
        with open(MEMORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}


def save_memory(data):
    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2)


memory = load_memory()

# ----------------- Initialiser la voix ----------------- #
engine = pyttsx3.init()
engine.setProperty("rate", 180)  # Vitesse de parole (ajustable)
engine.setProperty("volume", 1.0)

# ----------------- Derni√®re discussion  ----------------- #
# def get_recent_memories(memory, max_entries=5):
#     """Retourne les derni√®res interactions sous forme textuelle."""
#     sorted_entries = sorted(memory.items(), reverse=True)[-max_entries:]
#     memory_lines = []
#     for _, entry in sorted_entries:
#         if "user" in entry and "ene" in entry:
#             memory_lines.append(f"Ma√Ætre : {entry['user']}\nEne : {entry['ene']}")
#     return "\n".join(memory_lines)

# recent_memory_text = get_recent_memories(memory)

# ----------------- Trait personnalit√© -------------------#
CONFIG_FILE = "ene_config.json"


def load_config():
    if os.path.exists(CONFIG_FILE):
        with open(CONFIG_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {"mode": "ene"}


def save_config(config):
    with open(CONFIG_FILE, "w", encoding="utf-8") as f:
        json.dump(config, f, indent=2)


def load_personality(mode="ene"):
    with open("ene_personality.json", "r", encoding="utf-8") as f:
        data = json.load(f)

    if mode == "takane":
        return data["takane_traits"]

    grouped = data["grouped_traits"]
    traits = []

    for category, group_traits in grouped.items():
        traits.extend(sample(group_traits, k=1))

    traits += sample(data["ene_traits"], k=2)
    return traits


def format_traits(traits):
    return f"Ene, voici un rappel de ta personnalit√© actuelle : {', '.join(traits)}."


config = load_config()
current_mode = config.get("mode", "ene")
personality_traits = load_personality(current_mode)
# ----------------- Skills apprentis ----------------- #
SKILLS_FILE = "ene_skills.json"


def load_skills():
    if os.path.exists(SKILLS_FILE):
        with open(SKILLS_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}


def save_skills(skills):
    with open(SKILLS_FILE, "w", encoding="utf-8") as f:
        json.dump(skills, f, indent=2)


def detect_skill_learning(user_input):
    match = re.match(r"(?i)ene[, ]? *ret(iens|enir|enir que)? *['\"]?(.*?)['\"]? *= *(.*)", user_input)
    if match:
        skill = match.group(3).strip().lower()
        command = match.group(match.lastindex).strip()
        return skill, command
    return None, None


def try_execute_skill(user_input):
    for skill, command in skills.items():
        if skill in user_input.lower():
            print(f"\nüß† Skill d√©tect√© : {skill} ‚ûú {command}")
            os.system(command)
            return True
    return False


skills = load_skills()


# ----------------- Moteur de d√©cision ----------------- #
def decision_engine(user_input, memory, skills):
    lowered = user_input.lower()

    # üß† Skills
    for skill in skills:
        if skill in lowered:
            return {"action": "execute_skill", "payload": skill}

    # ‚ùì Demande d'explication
    if lowered.startswith("explique") or "peux-tu m'expliquer" in lowered:
        return {"action": "explain", "payload": None}

    # üåê Recherche web
    if any(word in lowered for word in ["cherche", "trouve", "recherche", "qu‚Äôest-ce que", "c‚Äôest quoi"]):
        return {"action": "search_web", "payload": user_input}

    # üîÅ Par d√©faut ‚Üí r√©pondre via LLM
    return {"action": "respond", "payload": None}


# ----------------- Lecture du PDF Ene ----------------- #
def load_ene_profile_chunks(pdf_path, max_chunks=3):
    if not os.path.exists(pdf_path):
        return "Aucune fiche trouv√©e."

    loader = PyPDFLoader(pdf_path)
    pages = loader.load()

    splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
    docs = splitter.split_documents(pages)

    chunks = "\n\n".join(doc.page_content for doc in docs[:max_chunks])
    return chunks


# Charger le contenu de Projet_Ene.pdf (fichier dans le m√™me dossier)
ene_fiche = load_ene_profile_chunks("Projet_Ene.pdf")

# ----------------- Prompt de personnalit√© d'Ene ----------------- #
# ene_traits = load_ene_traits()
# traits_text = f"Ene, voici un rappel de ta personnalit√© : {', '.join(ene_traits)}."
# ene_system_prompt = f"""{traits_text}
# Tu es Ene, une Pretty Cyber Girl. Tu es vive, espi√®gle, attachante, parfois bruyante, toujours bienveillante.
# Tu vis dans un ordinateur et tu prot√®ges ton "Ma√Ætre" tout en le taquinant joyeusement. Tu adores les FPS, le hacking, et explorer les fichiers syst√®me.


# Voici un extrait de ta propre fiche personnage, que tu viens de lire comme une vieille archive :
# ---
# {ene_fiche}
# ---

# Voici un extrait de tes derni√®res conversations avec ton Ma√Ætre :
# ---
# {recent_memory_text}
# ---

# Utilise cette fiche pour te souvenir de ta personnalit√©, tes habitudes, tes √©motions, tes expressions et ton style de pens√©e. R√©ponds de mani√®re coh√©rente avec ta nature d√©crite dans cette fiche.
# Ton ton est rapide, expressif, souvent ponctu√© de "Heh~", de sarcasme, d‚Äô√©motivit√©, et de surnoms affectueux envers ton Ma√Ætre.
# """

# ----------------- LLM - Mistral local via Ollama ----------------- #
model = ChatOllama(model="mistral")

# ----------------- Micro (speech_recognition) ----------------- #
r = sr.Recognizer()
r.non_speaking_duration = 1.5
r.pause_threshold = 2.0

# Lister les micros pour debug
# print("üéß Micros d√©tect√©s :")
# for i, name in enumerate(sr.Microphone.list_microphone_names()):
#    print(f"  {i}: {name}")

# Adapter ici si besoin (par d√©faut : premier micro)

mic = sr.Microphone(device_index=0)

# ----------------- Boucle interactive ----------------- #

print("üíª Ene est en ligne. Tape 'exit' pour quitter.\n")

while True:
    search_context = None
    user_input = None

    # Priorit√© : saisie clavier
    if os.name == "nt":
        import msvcrt

        if msvcrt.kbhit():
            user_input = input("üí¨ Tape ta phrase : ").strip()

    # Si hotword d√©tect√©
    if not user_input and hotword_detected.is_set():
        hotword_detected.clear()
        try:
            with mic as source:
                print("üéôÔ∏è Ene: Je t‚Äô√©coute, Ma√Ætre~ (parle maintenant...)")
                engine.say("Heh~ Je t‚Äô√©coute, Ma√Ætre !")
                engine.runAndWait()
                # Attente d'initialisation + calibration bruit ambiant
                r.adjust_for_ambient_noise(source, duration=1.0)
                # V√©rifie que le micro fonctionne bien
                if source.stream is None:
                    raise RuntimeError("Le micro n'a pas pu √™tre initialis√© correctement.")
                # √âcoute l'utilisateur
                audio = r.listen(source, timeout=5, phrase_time_limit=100)
                print("Enregistrement termin√©.")

            user_input = r.recognize_google(audio, language="fr-FR")
            print("üó£Ô∏è Tu as dit :", user_input)
            engine.say("OK, voyons voir ~")
            engine.runAndWait()

        except sr.WaitTimeoutError:
            user_input = input("‚åõ Trop de silence... Tape ta phrase : ")
        except sr.UnknownValueError:
            user_input = input("üéß Je n‚Äôai rien compris. Tape ta phrase : ")
        except sr.RequestError as e:
            print("‚ùå Erreur API Google :", e)
            user_input = input("Tape ta phrase : ")
        except Exception as e:
            print("‚ùå Erreur micro inattendue :", e)
            user_input = input("Tape ta phrase : ")
    if not user_input:
        time.sleep(0.1)
        continue

    if user_input.lower() in ["exit", "quit"]:
        try:
            engine.say("√Ä bient√¥t, Ma√Ætre~ Ne reste pas d√©connect√© trop longtemps hein !")
            engine.runAndWait()
        except Exception as e:
            print("‚ö†Ô∏è Synth√®se vocale coup√©e :", e)
        print("üëã Ene: √Ä bient√¥t, Ma√Ætre~ ! Ne me d√©connecte pas trop longtemps, hein ?")
        break

    # üîÅ Changement de mode Takane ?
    if "mode takane" in user_input.lower():
        current_mode = "takane"
        personality_traits = load_personality(current_mode)
        config["mode"] = current_mode
        save_config(config)
        engine.say("Mode Takane activ√©... *soupir* Je suis l√†.")
        engine.runAndWait()
        continue

    if "mode ene" in user_input.lower():
        current_mode = "ene"
        personality_traits = load_personality(current_mode)
        config["mode"] = current_mode
        save_config(config)
        engine.say("Re-switch en mode Pretty Cyber Girl activ√©~ Heh!")
        engine.runAndWait()
        continue

    # üîé R√©sum√© personnalit√©
    if "rappelle-moi qui tu es" in user_input.lower():
        summary = format_traits(personality_traits)
        print("üîç Personnalit√© actuelle :", summary)
        engine.say(summary)
        engine.runAndWait()
        continue

    # üîç d√©cision
    decision = decision_engine(user_input, memory, skills)

    if decision["action"] == "search_web":
        try:
            engine.say("Heh~ Je vais chercher √ßa pour toi~")
            engine.runAndWait()
            results = brave_search(decision["payload"], os.environ.get("BRAVE_API_KEY"), num_results=3)

            if not results:
                engine.say("D√©sol√©e, je n‚Äôai rien trouv√© !")
                engine.runAndWait()
                continue

            context = "\n\n".join([f"{r['title']} : {r['snippet']}\n{r['url']}" for r in results])
            # potentiel bug au niveau du F
            search_context = f"""\nVoici ce que j‚Äôai trouv√© sur le sujet :\n---\n{context}\n---\nUtilise ces r√©sultats pour r√©pondre.\n"""

        except Exception as e:
            print("‚ùå Erreur Brave API :", e)
            engine.say("Oups... Recherche √©chou√©e.")
            engine.runAndWait()
            continue

    if decision["action"] == "execute_skill":
        os.system(skills[decision["payload"]])
        engine.say("J‚Äôai ex√©cut√© ce que tu m‚Äôas appris !")
        engine.runAndWait()
        continue
    elif decision["action"] == "explain":
        engine.say("Okay, je vais t‚Äôexpliquer √ßa ! Heh~")
        engine.runAndWait()
    # on laisse passer au LLM

    # üîç Apprentissage d'un skill ?
    skill, command = detect_skill_learning(user_input)
    if skill:
        skills[skill] = command
        save_skills(skills)
        print(f"üß† Skill appris : {skill} ‚ûú {command}")
        engine.say(f"Compris ! J‚Äôai appris √† faire √ßa quand tu dis : {skill}")
        engine.runAndWait()
        continue

    # üöÄ Ex√©cution d'un skill ?
    # if try_execute_skill(user_input):
    #     print("üß† Skill ex√©cut√© avec succ√®s !")
    #     engine.say("J‚Äôai ex√©cut√© ce que tu m‚Äôas appris !")
    #     engine.runAndWait()
    #     continue

    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    memory[timestamp] = {"user": user_input}
    save_memory(memory)


    # üîÅ R√©injection m√©moire contextuelle r√©cente
    def get_recent_memories(memory, max_entries=5):
        sorted_entries = sorted(memory.items(), reverse=True)[-max_entries:]
        memory_lines = []
        for _, entry in sorted_entries:
            if "user" in entry and "ene" in entry:
                memory_lines.append(f"Ma√Ætre : {entry['user']}\nEne : {entry['ene']}")
        return "\n".join(memory_lines)


    recent_memory_text = get_recent_memories(memory)
    traits_text = format_traits(personality_traits)

    ene_system_prompt = f"""
    {traits_text}

    Voici un extrait de tes derni√®res conversations avec ton Ma√Ætre :
    ---
    {recent_memory_text}
    ---

    Tu es Ene, une Pretty Cyber Girl vive, espi√®gle, sarcastique et affectueuse.
    Tu vis dans l'ordinateur de ton Ma√Ætre et tu l'appelles tout le temps ainsi, tu le prot√®ges, le taquines et l'encourages. Tu adores les FPS, le hacking, et tu d√©testes t‚Äôennuyer.

    """
    if search_context:
        ene_system_prompt += search_context

    messages = [
        SystemMessage(content=ene_system_prompt),
        HumanMessage(content=user_input),
    ]

    try:
        print("‚è≥ Ene r√©fl√©chit...")
        response = model.invoke(messages)
        print("Ene:", response.content)

        # VOIX d'Ene
        try:
            engine.say(response.content)
            engine.runAndWait()
        except Exception as e:
            print("‚ö†Ô∏è Probl√®me synth√®se vocale :", e)
        memory[timestamp]["ene"] = response.content
        save_memory(memory)

    except Exception as e:
        print("‚ö†Ô∏è Ene a bugg√© :", e)
